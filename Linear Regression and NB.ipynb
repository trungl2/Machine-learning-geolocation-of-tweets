{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocesses the file into a usable format\n",
    "def preprocess(file_name):\n",
    "    \n",
    "    data = []\n",
    "    is_header = True\n",
    "    with open(file_name) as file:\n",
    "        for line in file:\n",
    "            \n",
    "            \n",
    "            if(is_header):\n",
    "                is_header = False\n",
    "                continue\n",
    "            \n",
    "            line=line.strip().split(\",\")\n",
    "            \n",
    "            data.append(line)\n",
    "    \n",
    "    return tuple(data);\n",
    "train_data10 = preprocess(\"train-top10.csv\")\n",
    "train_data100 = preprocess(\"train-top100.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove all zero vectors\n",
    "def remove_non_zero(data):\n",
    "    non_zero_train_data = []\n",
    "\n",
    "    for line in data:\n",
    "        for i in range(len(line[1:-1])):\n",
    "            if (line[i+1] != '0'):\n",
    "                non_zero_train_data.append(line)\n",
    "                break\n",
    "    return non_zero_train_data\n",
    "\n",
    "\n",
    "\n",
    "non_zero_train_data10 = remove_non_zero(train_data10)\n",
    "non_zero_train_data100 = remove_non_zero(train_data100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = frequency of the top words within the tweet, y = classes\n",
    "def get_training(train_data):\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "\n",
    "    for line in train_data:\n",
    "\n",
    "        token_freq = line[1:-1]\n",
    "\n",
    "        token_freq = list(map(int, token_freq))\n",
    "\n",
    "        X_train.append(token_freq)\n",
    "        y_train.append(line[-1])\n",
    "        \n",
    "    return X_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trains the data on both with zero and non-zero data sets\n",
    "non_zero_X_train10 , non_zero_y_train10 = get_training(non_zero_train_data10)\n",
    "non_zero_X_train100 , non_zero_y_train100 = get_training(non_zero_train_data100)\n",
    "X_train10, y_train10 = get_training(train_data10)\n",
    "X_train100, y_train100 = get_training(train_data100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bernoulliNB\n",
      "top 10 non-zero vectors accuracy: 0.7549213898797728\n",
      "top 100 non-zero vectors accuracy: 0.6128102550866777\n",
      "top 10 vectors accuracy: 0.29276968328887065\n",
      "top 100 vectors accuracy: 0.33762324958713225\n"
     ]
    }
   ],
   "source": [
    "#Used Bernoulli NB with hold out method to generate accuracies\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "bnb = BernoulliNB()\n",
    "\n",
    "non_zero_train10_acc = []\n",
    "non_zero_train100_acc = []\n",
    "train10_acc = []\n",
    "train100_acc = []\n",
    "\n",
    "for i in range(3):\n",
    "    \n",
    "    X_train_samp, X_test_samp, y_train_samp, y_test_samp = train_test_split(non_zero_X_train10, non_zero_y_train10, test_size=0.33, random_state=i)\n",
    "    bnb.fit(X_train_samp, y_train_samp)\n",
    "    non_zero_train10_acc.append(bnb.score(X_test_samp, y_test_samp))\n",
    "\n",
    "    X_train_samp, X_test_samp, y_train_samp, y_test_samp = train_test_split(non_zero_X_train100, non_zero_y_train100, test_size=0.33, random_state=i)\n",
    "    bnb.fit(X_train_samp, y_train_samp)\n",
    "    non_zero_train100_acc.append(bnb.score(X_test_samp, y_test_samp))\n",
    "    \n",
    "    X_train_samp, X_test_samp, y_train_samp, y_test_samp = train_test_split(X_train10, y_train10, test_size=0.33, random_state=i)\n",
    "    bnb.fit(X_train_samp, y_train_samp)\n",
    "    train10_acc.append(bnb.score(X_test_samp, y_test_samp))\n",
    "\n",
    "    X_train_samp, X_test_samp, y_train_samp, y_test_samp = train_test_split(X_train100, y_train100, test_size=0.33, random_state=i)\n",
    "    bnb.fit(X_train_samp, y_train_samp)\n",
    "    train100_acc.append(bnb.score(X_test_samp, y_test_samp))\n",
    "\n",
    "print(\"bernoulliNB\")\n",
    "print(\"top 10 non-zero vectors accuracy:\", np.mean(non_zero_train10_acc))\n",
    "print(\"top 100 non-zero vectors accuracy:\", np.mean(non_zero_train100_acc))\n",
    "print(\"top 10 vectors accuracy:\", np.mean(train10_acc))\n",
    "print(\"top 100 vectors accuracy:\", np.mean(train100_acc))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB\n",
      "top 10 non-zero vectors accuracy: 0.7536002113885586\n",
      "top 100 non-zero vectors accuracy: 0.6136275648470769\n",
      "top 10 vectors accuracy: 0.2846100475897316\n",
      "top 100 vectors accuracy: 0.33074374835097187\n"
     ]
    }
   ],
   "source": [
    "#Used Multinomial NB with hold out method to generate accuracies\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "mnb = MultinomialNB()\n",
    "\n",
    "non_zero_train10_acc = []\n",
    "non_zero_train100_acc = []\n",
    "train10_acc = []\n",
    "train100_acc = []\n",
    "\n",
    "for i in range(3):\n",
    "    \n",
    "    X_train_samp, X_test_samp, y_train_samp, y_test_samp = train_test_split(non_zero_X_train10, non_zero_y_train10, test_size=0.33, random_state=i)\n",
    "    mnb.fit(X_train_samp, y_train_samp)\n",
    "    non_zero_train10_acc.append(mnb.score(X_test_samp, y_test_samp))\n",
    "\n",
    "    X_train_samp, X_test_samp, y_train_samp, y_test_samp = train_test_split(non_zero_X_train100, non_zero_y_train100, test_size=0.33, random_state=i)\n",
    "    mnb.fit(X_train_samp, y_train_samp)\n",
    "    non_zero_train100_acc.append(mnb.score(X_test_samp, y_test_samp))\n",
    "    \n",
    "    X_train_samp, X_test_samp, y_train_samp, y_test_samp = train_test_split(X_train10, y_train10, test_size=0.33, random_state=i)\n",
    "    mnb.fit(X_train_samp, y_train_samp)\n",
    "    train10_acc.append(mnb.score(X_test_samp, y_test_samp))\n",
    "\n",
    "    X_train_samp, X_test_samp, y_train_samp, y_test_samp = train_test_split(X_train100, y_train100, test_size=0.33, random_state=i)\n",
    "    mnb.fit(X_train_samp, y_train_samp)\n",
    "    train100_acc.append(mnb.score(X_test_samp, y_test_samp))\n",
    "\n",
    "print(\"MultinomialNB\")\n",
    "print(\"top 10 non-zero vectors accuracy:\", np.mean(non_zero_train10_acc))\n",
    "print(\"top 100 non-zero vectors accuracy:\", np.mean(non_zero_train100_acc))\n",
    "print(\"top 10 vectors accuracy:\", np.mean(train10_acc))\n",
    "print(\"top 100 vectors accuracy:\", np.mean(train100_acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression\n",
      "top 10 non-zero vectors accuracy: 0.768001056942793\n",
      "top 100 non-zero vectors accuracy: 0.6192627005635135\n",
      "top 10 vectors accuracy: 0.28983807764846137\n",
      "top 100 vectors accuracy: 0.33563952977045525\n"
     ]
    }
   ],
   "source": [
    "#Used LogisticRegression with hold out method to generate accuracies\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression()\n",
    "\n",
    "non_zero_train10_acc = []\n",
    "non_zero_train100_acc = []\n",
    "train10_acc = []\n",
    "train100_acc = []\n",
    "\n",
    "for i in range(3):\n",
    "    \n",
    "    X_train_samp, X_test_samp, y_train_samp, y_test_samp = train_test_split(non_zero_X_train10, non_zero_y_train10, test_size=0.33, random_state=i)\n",
    "    lr.fit(X_train_samp, y_train_samp)\n",
    "    non_zero_train10_acc.append(lr.score(X_test_samp, y_test_samp))\n",
    "\n",
    "    X_train_samp, X_test_samp, y_train_samp, y_test_samp = train_test_split(non_zero_X_train100, non_zero_y_train100, test_size=0.33, random_state=i)\n",
    "    lr.fit(X_train_samp, y_train_samp)\n",
    "    non_zero_train100_acc.append(lr.score(X_test_samp, y_test_samp))\n",
    "    \n",
    "    X_train_samp, X_test_samp, y_train_samp, y_test_samp = train_test_split(X_train10, y_train10, test_size=0.33, random_state=i)\n",
    "    lr.fit(X_train_samp, y_train_samp)\n",
    "    train10_acc.append(lr.score(X_test_samp, y_test_samp))\n",
    "\n",
    "    X_train_samp, X_test_samp, y_train_samp, y_test_samp = train_test_split(X_train100, y_train100, test_size=0.33, random_state=i)\n",
    "    lr.fit(X_train_samp, y_train_samp)\n",
    "    train100_acc.append(lr.score(X_test_samp, y_test_samp))\n",
    "\n",
    "print(\"Logistic regression\")\n",
    "print(\"top 10 non-zero vectors accuracy:\", np.mean(non_zero_train10_acc))\n",
    "print(\"top 100 non-zero vectors accuracy:\", np.mean(non_zero_train100_acc))\n",
    "print(\"top 10 vectors accuracy:\", np.mean(train10_acc))\n",
    "print(\"top 100 vectors accuracy:\", np.mean(train100_acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1217, 309, 255, 313], [6894, 7657, 6820, 6872], [180, 324, 1162, 291], [273, 199, 300, 1045]]\n"
     ]
    }
   ],
   "source": [
    "#error analysis with mnb\n",
    "import random\n",
    "\n",
    "locs = [\"Brisbane\", \"Perth\", \"Melbourne\", \"Sydney\"]\n",
    "locs = [[0,0,0,0], [0,0,0,0], [0,0,0,0], [0,0,0,0]]\n",
    "\n",
    "rand_num = random.randint(1,100000)\n",
    "\n",
    "X_train_samp, X_test_samp, y_train_samp, y_test_samp = train_test_split(X_train100, y_train100, test_size=0.33, random_state=4)\n",
    "mnb.fit(X_train_samp, y_train_samp)\n",
    "\n",
    "for i in range(len(X_test_samp)):\n",
    "    pred = mnb.predict([X_test_samp[i]])\n",
    "    if pred == \"Brisbane\":\n",
    "        if y_test_samp[i] == \"Brisbane\":\n",
    "            locs[0][0] += 1\n",
    "        if y_test_samp[i]  == \"Perth\":\n",
    "            locs[0][1] += 1\n",
    "        if y_test_samp[i]  == \"Melbourne\":\n",
    "            locs[0][2] += 1\n",
    "        if y_test_samp[i]  == \"Sydney\":\n",
    "            locs[0][3] += 1\n",
    "    if pred == \"Perth\":\n",
    "        if y_test_samp[i]  == \"Brisbane\":\n",
    "            locs[1][0] += 1\n",
    "        if y_test_samp[i]  == \"Perth\":\n",
    "            locs[1][1] += 1\n",
    "        if y_test_samp[i]  == \"Melbourne\":\n",
    "            locs[1][2] += 1\n",
    "        if y_test_samp[i]  == \"Sydney\":\n",
    "            locs[1][3] += 1\n",
    "    if pred == \"Melbourne\":\n",
    "        if y_test_samp[i]  == \"Brisbane\":\n",
    "            locs[2][0] += 1\n",
    "        if y_test_samp[i]  == \"Perth\":\n",
    "            locs[2][1] += 1\n",
    "        if y_test_samp[i]  == \"Melbourne\":\n",
    "            locs[2][2] += 1\n",
    "        if y_test_samp[i] == \"Sydney\":\n",
    "            locs[2][3] += 1\n",
    "    if pred == \"Sydney\":\n",
    "        if y_test_samp[i]  == \"Brisbane\":\n",
    "            locs[3][0] += 1\n",
    "        if y_test_samp[i]  == \"Perth\":\n",
    "            locs[3][1] += 1\n",
    "        if y_test_samp[i]  == \"Melbourne\":\n",
    "            locs[3][2] += 1\n",
    "        if y_test_samp[i]  == \"Sydney\":\n",
    "            locs[3][3] += 1\n",
    "print(locs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1209, 352, 247, 336], [6765, 7803, 6806, 6838], [190, 307, 1154, 282], [273, 209, 248, 1092]]\n"
     ]
    }
   ],
   "source": [
    "#error analysis with lr\n",
    "import random\n",
    "\n",
    "locs = [\"Brisbane\", \"Perth\", \"Melbourne\", \"Sydney\"]\n",
    "locs = [[0,0,0,0], [0,0,0,0], [0,0,0,0], [0,0,0,0]]\n",
    "\n",
    "rand_num = random.randint(1,100000)\n",
    "\n",
    "X_train_samp, X_test_samp, y_train_samp, y_test_samp = train_test_split(X_train100, y_train100, test_size=0.33, random_state=7)\n",
    "lr.fit(X_train_samp, y_train_samp)\n",
    "\n",
    "for i in range(len(X_test_samp)):\n",
    "    pred = mnb.predict([X_test_samp[i]])\n",
    "    if pred == \"Brisbane\":\n",
    "        if y_test_samp[i] == \"Brisbane\":\n",
    "            locs[0][0] += 1\n",
    "        if y_test_samp[i]  == \"Perth\":\n",
    "            locs[0][1] += 1\n",
    "        if y_test_samp[i]  == \"Melbourne\":\n",
    "            locs[0][2] += 1\n",
    "        if y_test_samp[i]  == \"Sydney\":\n",
    "            locs[0][3] += 1\n",
    "    if pred == \"Perth\":\n",
    "        if y_test_samp[i]  == \"Brisbane\":\n",
    "            locs[1][0] += 1\n",
    "        if y_test_samp[i]  == \"Perth\":\n",
    "            locs[1][1] += 1\n",
    "        if y_test_samp[i]  == \"Melbourne\":\n",
    "            locs[1][2] += 1\n",
    "        if y_test_samp[i]  == \"Sydney\":\n",
    "            locs[1][3] += 1\n",
    "    if pred == \"Melbourne\":\n",
    "        if y_test_samp[i]  == \"Brisbane\":\n",
    "            locs[2][0] += 1\n",
    "        if y_test_samp[i]  == \"Perth\":\n",
    "            locs[2][1] += 1\n",
    "        if y_test_samp[i]  == \"Melbourne\":\n",
    "            locs[2][2] += 1\n",
    "        if y_test_samp[i] == \"Sydney\":\n",
    "            locs[2][3] += 1\n",
    "    if pred == \"Sydney\":\n",
    "        if y_test_samp[i]  == \"Brisbane\":\n",
    "            locs[3][0] += 1\n",
    "        if y_test_samp[i]  == \"Perth\":\n",
    "            locs[3][1] += 1\n",
    "        if y_test_samp[i]  == \"Melbourne\":\n",
    "            locs[3][2] += 1\n",
    "        if y_test_samp[i]  == \"Sydney\":\n",
    "            locs[3][3] += 1\n",
    "print(locs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
